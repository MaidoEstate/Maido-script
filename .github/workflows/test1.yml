name: Scrape and Upload to Webflow

on:
  workflow_dispatch:

jobs:
  scrape-and-upload:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout Repository
      - name: Checkout Repository
        uses: actions/checkout@v3

      # Step 2: Set Up Python Environment
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.11

      # Step 3: Install Playwright and Dependencies
      - name: Install Playwright and Dependencies
        run: |
          pip install playwright
          playwright install

      # Step 4: Install Python Dependencies
      - name: Install Dependencies
        run: |
          pip install -r requirements.txt

      # Step 5: Run the Test Script
      - name: Run Test Script
        env:
          START_PAGE: 12498
          OUTPUT_DIR: ./scraped_data
          GITHUB_PAT: ${{ secrets.PAT }}
          WEBFLOW_API_TOKEN: ${{ secrets.WEBFLOW_API_TOKEN }}
          WEBFLOW_COLLECTION_ID: "665b06933a06a0a4893b7af2"
          CLOUDINARY_CLOUD_NAME: ${{ secrets.CLOUDINARY_CLOUD_NAME }}
          CLOUDINARY_API_KEY: ${{ secrets.CLOUDINARY_API_KEY }}
          CLOUDINARY_API_SECRET: ${{ secrets.CLOUDINARY_API_SECRET }}
        run: |
          echo "Running the scraper script with Playwright..."
          python test1.py
